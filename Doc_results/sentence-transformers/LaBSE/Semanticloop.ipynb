{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817d3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EcoTech Solutions S.r.l.\n",
      "\n",
      "per GreenLife S.p.A. Via dell'Innovazione 42, 20121 Milano (MI), Italia\n",
      "\n",
      "Soluzioni di Intelligenza Artificiale per l'Ottimizzazione del Processo di Riciclo Industriale\n",
      "\n",
      "Implementazione di Sistemi AI per l'Analisi dei Materiali e l'Efficienza Energetica\n",
      "\n",
      "## Proposta contrattuale\n",
      "\n",
      "Versione: 1.3 Validità: 60 giorni\n",
      "\n",
      "Destinatario: Marco Bianchi m.bianchi@greenlifespa.eu Laura Verdi l.verdi@greenlifespa.eu Andrea Rossi a.rossi@greenlifespa.eu\n",
      "\n",
      "Redatta da: Dott.ssa Elena M\n"
     ]
    }
   ],
   "source": [
    "# This is a long document we can split up.\n",
    "with open(\"/storage/data_4T_b/andreacutuli/PROVA/Scripts/result_document.md\") as f:\n",
    "    fac_simile = f.read()\n",
    "print(fac_simile[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c991aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# Usa un modello open-source per gli embeddings (gratuito, nessuna chiave API richiesta)\n",
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"Musixmatch/umberto-commoncrawl-cased-v1\")\n",
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "    #model_name=\"sentence-transformers/LaBSE\"\n",
    "    model_kwargs={\"use_auth_token\": \"[REMOVED]\"}\n",
    ")\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
    "model=embedding_model\n",
    "\n",
    "\n",
    "# Inizializza il semantic chunker con quel modello\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"gradient\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''semantic_chunker = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=95,\n",
    "    min_chunk_size=300,\n",
    "    max_chunk_size=1000,\n",
    "    buffer_size=50,\n",
    "    embedding_batch_size=8\n",
    ")\n",
    "semantic_chunks = semantic_chunker.create_documents([fac_simile])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7dccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_chunks = semantic_chunker.create_documents([fac_simile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"semantic_chunks.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, doc in enumerate(semantic_chunks):\n",
    "        f.write(f\"### Chunk {i + 1}\\n\\n\")\n",
    "        f.write(doc.page_content.strip() + \"\\n\\n\")\n",
    "print(f\"File salvato come semantic_chunks.md\")\n",
    "\n",
    "print(f\"Numero di chunk creati: {len(semantic_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Lista modelli embedding da testare (se vuoi testarne più di uno)\n",
    "embedding_models = [\n",
    "    HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\", model_kwargs={\"use_auth_token\": \"[REMOVED]\"}),\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/LaBSE\"),\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    HuggingFaceEmbeddings(model_name=\"nickprock/sentence-bert-base-italian-uncased\"),\n",
    "    HuggingFaceEmbeddings(model_name=\"nickprock/multi-sentence-BERTino\", model_kwargs={\"use_auth_token\": \"[REMOVED]\"}),\n",
    "\n",
    "]\n",
    "\n",
    "# Lista di configurazioni per SemanticChunker da testare\n",
    "chunker_configs = [\n",
    "    # ● Solo “gradient” per transizioni semantiche pure, con contesto ampio\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"gradient\",\n",
    "        \"buffer_size\": 80,\n",
    "        \"embedding_batch_size\": 16,\n",
    "    },\n",
    "\n",
    "    # ● Percentile (soglie alte → chunk più corposi)\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"percentile\",\n",
    "        \"breakpoint_threshold_amount\": 95,\n",
    "        \"buffer_size\": 80,\n",
    "        \"embedding_batch_size\": 16,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"percentile\",\n",
    "        \"breakpoint_threshold_amount\": 90,\n",
    "        \"buffer_size\": 70,\n",
    "        \"embedding_batch_size\": 16,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"percentile\",\n",
    "        \"breakpoint_threshold_amount\": 85,\n",
    "        \"buffer_size\": 60,\n",
    "        \"embedding_batch_size\": 12,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"percentile\",\n",
    "        \"breakpoint_threshold_amount\": 80,\n",
    "        \"buffer_size\": 50,\n",
    "        \"embedding_batch_size\": 8,\n",
    "    },\n",
    "\n",
    "    # ● Deviazione standard (multipli più alti → tagli più “accorti”)\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"standard_deviation\",\n",
    "        \"breakpoint_threshold_amount\": 1.0,\n",
    "        \"buffer_size\": 80,\n",
    "        \"embedding_batch_size\": 16,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"standard_deviation\",\n",
    "        \"breakpoint_threshold_amount\": 0.75,\n",
    "        \"buffer_size\": 60,\n",
    "        \"embedding_batch_size\": 12,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"standard_deviation\",\n",
    "        \"breakpoint_threshold_amount\": 0.5,\n",
    "        \"buffer_size\": 40,\n",
    "        \"embedding_batch_size\": 8,\n",
    "    },\n",
    "\n",
    "    # ● Interquartile range (IQR)\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"interquartile\",\n",
    "        \"breakpoint_threshold_amount\": 1.5,\n",
    "        \"buffer_size\": 80,\n",
    "        \"embedding_batch_size\": 16,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"interquartile\",\n",
    "        \"breakpoint_threshold_amount\": 1.0,\n",
    "        \"buffer_size\": 60,\n",
    "        \"embedding_batch_size\": 12,\n",
    "    },\n",
    "    {\n",
    "        \"breakpoint_threshold_type\": \"interquartile\",\n",
    "        \"breakpoint_threshold_amount\": 0.75,\n",
    "        \"buffer_size\": 40,\n",
    "        \"embedding_batch_size\": 8,\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e134f818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test numero 45 con config: {'breakpoint_threshold_type': 'gradient', 'buffer_size': 80, 'embedding_batch_size': 16} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_45.md\n",
      "Numero di chunk creati: 13\n",
      "\n",
      "Test numero 46 con config: {'breakpoint_threshold_type': 'percentile', 'breakpoint_threshold_amount': 95, 'buffer_size': 80, 'embedding_batch_size': 16} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_46.md\n",
      "Numero di chunk creati: 13\n",
      "\n",
      "Test numero 47 con config: {'breakpoint_threshold_type': 'percentile', 'breakpoint_threshold_amount': 90, 'buffer_size': 70, 'embedding_batch_size': 16} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_47.md\n",
      "Numero di chunk creati: 24\n",
      "\n",
      "Test numero 48 con config: {'breakpoint_threshold_type': 'percentile', 'breakpoint_threshold_amount': 85, 'buffer_size': 60, 'embedding_batch_size': 12} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_48.md\n",
      "Numero di chunk creati: 35\n",
      "\n",
      "Test numero 49 con config: {'breakpoint_threshold_type': 'percentile', 'breakpoint_threshold_amount': 80, 'buffer_size': 50, 'embedding_batch_size': 8} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_49.md\n",
      "Numero di chunk creati: 46\n",
      "\n",
      "Test numero 50 con config: {'breakpoint_threshold_type': 'standard_deviation', 'breakpoint_threshold_amount': 1.0, 'buffer_size': 80, 'embedding_batch_size': 16} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_50.md\n",
      "Numero di chunk creati: 24\n",
      "\n",
      "Test numero 51 con config: {'breakpoint_threshold_type': 'standard_deviation', 'breakpoint_threshold_amount': 0.75, 'buffer_size': 60, 'embedding_batch_size': 12} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_51.md\n",
      "Numero di chunk creati: 30\n",
      "\n",
      "Test numero 52 con config: {'breakpoint_threshold_type': 'standard_deviation', 'breakpoint_threshold_amount': 0.5, 'buffer_size': 40, 'embedding_batch_size': 8} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_52.md\n",
      "Numero di chunk creati: 41\n",
      "\n",
      "Test numero 53 con config: {'breakpoint_threshold_type': 'interquartile', 'breakpoint_threshold_amount': 1.5, 'buffer_size': 80, 'embedding_batch_size': 16} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_53.md\n",
      "Numero di chunk creati: 19\n",
      "\n",
      "Test numero 54 con config: {'breakpoint_threshold_type': 'interquartile', 'breakpoint_threshold_amount': 1.0, 'buffer_size': 60, 'embedding_batch_size': 12} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_54.md\n",
      "Numero di chunk creati: 27\n",
      "\n",
      "Test numero 55 con config: {'breakpoint_threshold_type': 'interquartile', 'breakpoint_threshold_amount': 0.75, 'buffer_size': 40, 'embedding_batch_size': 8} e modello nickprock/multi-sentence-BERTino\n",
      "File salvato come semantic_chunks_55.md\n",
      "Numero di chunk creati: 34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametri accettati da SemanticChunker (da adattare in base alla tua versione)\n",
    "accepted_keys = {\n",
    "    \"breakpoint_threshold_type\",\n",
    "    \"buffer_size\",\n",
    "    \"chunk_size\",\n",
    "    \"chunk_overlap\",\n",
    "    \"breakpoint_threshold_amount\",\n",
    "    # aggiungi qui altri parametri validi se ce ne sono\n",
    "}\n",
    "\n",
    "counter = 45\n",
    "for emb_model in embedding_models:\n",
    "    for config in chunker_configs:\n",
    "        print(f\"Test numero {counter} con config: {config} e modello {emb_model.model_name}\")\n",
    "        \n",
    "        # Filtra config per mantenere solo parametri accettati\n",
    "        filtered_config = {k: v for k, v in config.items() if k in accepted_keys}\n",
    "\n",
    "        semantic_chunker = SemanticChunker(\n",
    "            embeddings=emb_model,\n",
    "            **filtered_config\n",
    "        )\n",
    "        \n",
    "        semantic_chunks = semantic_chunker.create_documents([fac_simile])\n",
    "        \n",
    "        filename = f\"semantic_chunks_{counter}.md\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, doc in enumerate(semantic_chunks):\n",
    "                f.write(f\"### Chunk {i + 1}\\n\\n\")\n",
    "                f.write(doc.page_content.strip() + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"File salvato come {filename}\")\n",
    "        print(f\"Numero di chunk creati: {len(semantic_chunks)}\\n\")\n",
    "        \n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIGUTRAZIONE CONSIGLIATA DA CHAT GPT\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"gradient\",  # o \"percentile\" se vuoi sperimentare con soglie fisse\n",
    "    buffer_size=80,  # aumenta il contesto per rendere i chunk più coerenti\n",
    "    embedding_batch_size=16  # sfrutta la potenza del tuo computer\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrievers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
