{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb97477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pathlib import Path\n",
    "\n",
    "# Testo di esempio\n",
    "fac_simile = \"Il tuo testo lungo da chunkare va qui. Può essere un testo scientifico, un articolo, un documento legale ecc.\"\n",
    "\n",
    "# Modello di embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "    model_kwargs={\"use_auth_token\": os.getenv(\"HF_TOKEN\")}\n",
    ")\n",
    "\n",
    "# Configurazioni da testare SENZA specificare chunk size\n",
    "chunker_configs = [\n",
    "    {\"breakpoint_threshold_type\": \"gradient\"},\n",
    "\n",
    "    {\"breakpoint_threshold_type\": \"percentile\", \"breakpoint_threshold_amount\": 95},\n",
    "    {\"breakpoint_threshold_type\": \"percentile\", \"breakpoint_threshold_amount\": 90},\n",
    "    {\"breakpoint_threshold_type\": \"percentile\", \"breakpoint_threshold_amount\": 85},\n",
    "    {\"breakpoint_threshold_type\": \"percentile\", \"breakpoint_threshold_amount\": 80},\n",
    "\n",
    "    {\"breakpoint_threshold_type\": \"standard_deviation\", \"breakpoint_threshold_amount\": 1.0},\n",
    "    {\"breakpoint_threshold_type\": \"standard_deviation\", \"breakpoint_threshold_amount\": 0.75},\n",
    "    {\"breakpoint_threshold_type\": \"standard_deviation\", \"breakpoint_threshold_amount\": 0.5},\n",
    "\n",
    "    {\"breakpoint_threshold_type\": \"interquartile\", \"breakpoint_threshold_amount\": 1.5},\n",
    "    {\"breakpoint_threshold_type\": \"interquartile\", \"breakpoint_threshold_amount\": 1.0},\n",
    "    {\"breakpoint_threshold_type\": \"interquartile\", \"breakpoint_threshold_amount\": 0.75},\n",
    "]\n",
    "\n",
    "# Loop su tutte le configurazioni\n",
    "for idx, config in enumerate(chunker_configs):\n",
    "    print(f\"\\n--- Configurazione {idx + 1} ---\")\n",
    "    print(f\"Parametri: {config}\")\n",
    "\n",
    "    semantic_chunker = SemanticChunker(\n",
    "        embeddings=embedding_model,\n",
    "        **config  # Inserisce dinamicamente i parametri\n",
    "    )\n",
    "\n",
    "    semantic_chunks = semantic_chunker.create_documents([fac_simile])\n",
    "\n",
    "    filename = f\"semantic_chunks_config_{idx + 1}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, doc in enumerate(semantic_chunks):\n",
    "            f.write(f\"### Chunk {i + 1}\\n\\n\")\n",
    "            f.write(doc.page_content.strip() + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Salvato in: {filename}\")\n",
    "    print(f\"Numero di chunk creati: {len(semantic_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"gradient\",  # o \"percentile\" se vuoi sperimentare con soglie fisse\n",
    "    buffer_size=80,  # aumenta il contesto per rendere i chunk più coerenti\n",
    "    embedding_batch_size=16  # sfrutta la potenza del tuo computer\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
