{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa48b46",
   "metadata": {},
   "source": [
    "# ESTRAZIONE TABELLE E IMMAGINI DA PDF E OCR SU QUESTE UTILIZZANDO IL MODELLO GRANITE DI OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "IMAGE_RESOLUTION_SCALE = 2.0\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # cartella PDF in input\n",
    "    pdf_folder = Path(\"/storage/data_4T_b/andreacutuli/PROVA/Documents/pdf_fac_simile\")\n",
    "    # cartella radice dove verranno create le sottocartelle di output\n",
    "    output_root = Path(\"/storage/data_4T_b/andreacutuli/PROVA/Documents/output_images\")\n",
    "\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "    pipeline_options.generate_page_images = True\n",
    "    pipeline_options.generate_picture_images = True\n",
    "\n",
    "    doc_converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_time_global = time.time()\n",
    "\n",
    "    # Itera su tutti i PDF nella cartella\n",
    "    for input_doc_path in pdf_folder.glob(\"*.pdf\"):\n",
    "        if not input_doc_path.exists():\n",
    "            _log.warning(f\"PDF non trovato: {input_doc_path}\")\n",
    "            continue\n",
    "\n",
    "        # Crea la sottocartella di output per questo file\n",
    "        doc_filename = input_doc_path.stem\n",
    "        output_dir = output_root / doc_filename\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        conv_res = doc_converter.convert(str(input_doc_path))\n",
    "\n",
    "        # --- Da qui in poi Ã¨ TUTTO il tuo codice originale, invariato ---\n",
    "\n",
    "        # Save page images\n",
    "        pages_obj = getattr(conv_res.document, \"pages\", None)\n",
    "        if pages_obj is None:\n",
    "            _log.warning(\"Nessuna proprietÃ  pages trovata su conv_res.document\")\n",
    "        else:\n",
    "            try:\n",
    "                iterator = list(pages_obj.items())  # dict-like\n",
    "                is_dict = True\n",
    "            except Exception:\n",
    "                iterator = list(enumerate(pages_obj, start=1))  # list-like\n",
    "                is_dict = False\n",
    "\n",
    "            for key, page in iterator:\n",
    "                page_no = getattr(page, \"page_no\", None) or (key if is_dict else key)\n",
    "                page_image_filename = output_dir / f\"{doc_filename}-page-{page_no}.png\"\n",
    "                try:\n",
    "                    page_image = getattr(page, \"image\", None)\n",
    "                    if page_image is None:\n",
    "                        _log.debug(f\"Nessuna immagine pagina per page {page_no}\")\n",
    "                        continue\n",
    "                    pil_img = getattr(page_image, \"pil_image\", None)\n",
    "                    if pil_img is not None:\n",
    "                        pil_img.save(page_image_filename, format=\"PNG\")\n",
    "                    else:\n",
    "                        page_image.save(str(page_image_filename), format=\"PNG\")\n",
    "                except Exception as e:\n",
    "                    _log.exception(f\"Errore salvataggio immagine pagina {page_no}: {e}\")\n",
    "\n",
    "        # Save images of figures and tables\n",
    "        table_counter = 0\n",
    "        picture_counter = 0\n",
    "        try:\n",
    "            iterator = conv_res.document.iterate_items()\n",
    "        except Exception:\n",
    "            iterator = []\n",
    "\n",
    "        for element, _level in iterator:\n",
    "            try:\n",
    "                if isinstance(element, TableItem):\n",
    "                    table_counter += 1\n",
    "                    element_image_filename = output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
    "                    img = element.get_image(conv_res.document)\n",
    "                    if hasattr(img, \"save\"):\n",
    "                        img.save(element_image_filename, format=\"PNG\")\n",
    "                    else:\n",
    "                        with open(element_image_filename, \"wb\") as fp:\n",
    "                            fp.write(img)\n",
    "                elif isinstance(element, PictureItem):\n",
    "                    picture_counter += 1\n",
    "                    element_image_filename = output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
    "                    img = element.get_image(conv_res.document)\n",
    "                    if hasattr(img, \"save\"):\n",
    "                        img.save(element_image_filename, format=\"PNG\")\n",
    "                    else:\n",
    "                        with open(element_image_filename, \"wb\") as fp:\n",
    "                            fp.write(img)\n",
    "            except Exception as e:\n",
    "                _log.exception(f\"Errore salvataggio elemento {type(element)}: {e}\")\n",
    "\n",
    "        # Generazione manuale di markdown con segnaposto\n",
    "        md_lines = []\n",
    "        table_counter_md = 0\n",
    "        picture_counter_md = 0\n",
    "\n",
    "        try:\n",
    "            iterator = conv_res.document.iterate_items()\n",
    "        except Exception:\n",
    "            iterator = []\n",
    "\n",
    "        for element, _level in iterator:\n",
    "            try:\n",
    "                if isinstance(element, TableItem):\n",
    "                    table_counter_md += 1\n",
    "                    md_lines.append(f\"[[TABLE-{table_counter_md}]]\\n\")\n",
    "                elif isinstance(element, PictureItem):\n",
    "                    picture_counter_md += 1\n",
    "                    md_lines.append(f\"[[IMAGE-{picture_counter_md}]]\\n\")\n",
    "                else:\n",
    "                    testo = getattr(element, \"text\", \"\") or getattr(element, \"get_text\", lambda: \"\")()\n",
    "                    if testo:\n",
    "                        md_lines.append(testo + \"\\n\")\n",
    "            except Exception as e:\n",
    "                _log.exception(f\"Errore processando elemento {type(element)}: {e}\")\n",
    "\n",
    "        md_placeholder_filename = output_dir / f\"{doc_filename}-with-placeholders.md\"\n",
    "        try:\n",
    "            with open(md_placeholder_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\".join(md_lines))\n",
    "            print(f\"Markdown con segnaposto salvato in: {md_placeholder_filename}\")\n",
    "        except Exception as e:\n",
    "            _log.exception(f\"Errore salvataggio markdown con segnaposto: {e}\")\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        _log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")\n",
    "        _log.info(f\"Saved pages: {page_no if 'page_no' in locals() else 'n/a'}, tables: {table_counter}, pictures: {picture_counter}\")\n",
    "\n",
    "        for nome_file in os.listdir(output_dir):\n",
    "            percorso_file = os.path.join(output_dir, nome_file)\n",
    "            if os.path.isfile(percorso_file) and \"page\" in nome_file:\n",
    "                os.remove(percorso_file)\n",
    "                print(f\"Cancellato: {nome_file}\")\n",
    "\n",
    "    total_time = time.time() - start_time_global\n",
    "    _log.info(f\"Tutti i PDF elaborati in {total_time:.2f} secondi.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d06fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPOSTA TUTTI I FILE MARKDOWN IN UNA CARTELLA A PARTE\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Cartella sorgente\n",
    "source_dir = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/output_images\"\n",
    "\n",
    "# Cartella di destinazione\n",
    "dest_dir = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_placeholders\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# Itera ricorsivamente tutte le sottocartelle\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".md\"):\n",
    "            source_path = os.path.join(root, file)\n",
    "            dest_path = os.path.join(dest_dir, file)\n",
    "\n",
    "            # Sposta il file (sovrascrive se esiste giÃ )\n",
    "            shutil.move(source_path, dest_path)\n",
    "            print(f\"Spostato: {source_path} -> {dest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESSA TUTTE LE IMMAGINI CON OLLAMA E SALVA LE DESCRIZIONI IN FILE .TXT\n",
    "\n",
    "import os\n",
    "import ollama\n",
    "\n",
    "input_root = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/output_images\"\n",
    "descrizioni_root = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/descrizioni\"\n",
    "os.makedirs(descrizioni_root, exist_ok=True)\n",
    "\n",
    "# Modello Ollama\n",
    "model = \"granite3.2-vision\"\n",
    "prompt = \"Describe what's in this image.\"\n",
    "\n",
    "# Itera sulle sottocartelle nella cartella principale di input\n",
    "for subfolder in os.listdir(input_root):\n",
    "    subfolder_path = os.path.join(input_root, subfolder)\n",
    "    if not os.path.isdir(subfolder_path):\n",
    "        continue  # salta eventuali file direttamente in input_root\n",
    "\n",
    "    # Crea la sottocartella corrispondente per le descrizioni\n",
    "    output_subfolder = os.path.join(descrizioni_root, subfolder)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "    # Itera su ogni immagine nella sottocartella\n",
    "    for nome_file in os.listdir(subfolder_path):\n",
    "        percorso_file = os.path.join(subfolder_path, nome_file)\n",
    "\n",
    "        if os.path.isfile(percorso_file) and nome_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            print(f\"\\nProcessing image: {nome_file} in folder {subfolder}\")\n",
    "\n",
    "            # Esegui inferenza con Ollama\n",
    "            response = ollama.generate(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                images=[percorso_file]\n",
    "            )\n",
    "\n",
    "            descrizione = response['response']\n",
    "            print(\"Description:\", descrizione)\n",
    "\n",
    "            # Salva la descrizione in file .txt\n",
    "            txt_filename = os.path.splitext(nome_file)[0] + \".txt\"\n",
    "            txt_path = os.path.join(output_subfolder, txt_filename)\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(descrizione)\n",
    "            print(f\"[OK] Descrizione salvata in {txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aed8e1",
   "metadata": {},
   "source": [
    "# DIVISIONE IN CHUNKS CON SEMANTIC CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da85117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 40721.40it/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 2-with-placeholders_chunks.md (13 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 814 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 21-with-placeholders_chunks.md (3 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 1862 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 18-with-placeholders_chunks.md (5 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2205 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE Validazione-with-placeholders_chunks.md (5 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2940 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 14-with-placeholders_chunks.md (8 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 1294 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 12-with-placeholders_chunks.md (4 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 1912 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 17-with-placeholders_chunks.md (6 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 3011 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 19-with-placeholders_chunks.md (8 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2042 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 8-with-placeholders_chunks.md (6 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2225 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 20-with-placeholders_chunks.md (5 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2096 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 11-with-placeholders_chunks.md (6 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 3705 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 13-with-placeholders_chunks.md (9 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 5378 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 3-with-placeholders_chunks.md (13 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 5561 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 1-with-placeholders_chunks.md (13 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 494 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 5-with-placeholders_chunks.md (3 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 732 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 7-with-placeholders_chunks.md (3 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 5536 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 1.1-with-placeholders_chunks.md (13 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 1908 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 15-with-placeholders_chunks.md (5 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2138 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 10-with-placeholders_chunks.md (5 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2423 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 4-with-placeholders_chunks.md (7 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 676 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 6-with-placeholders_chunks.md (3 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 2634 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 9-with-placeholders_chunks.md (6 chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/data_4T_b/andreacutuli/miniconda3/envs/docling_env/lib/python3.11/site-packages/gliner/data_processing/processor.py:351: UserWarning: Sentence of length 782 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File salvato: /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks/FAC-SIMILE 16-with-placeholders_chunks.md (3 chunk)\n",
      "\n",
      "âœ… Tutti i documenti processati.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from gliner import GLiNER\n",
    "\n",
    "#Gliner per entity recognition fare in modo che i chunk non spezzino le entitÃ \n",
    "\n",
    "# === CONFIG ===\n",
    "SOURCE_FOLDER = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_placeholders\"  # cartella con .md\n",
    "OUTPUT_FOLDER = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks\"  # dove salvare chunk\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# === Inizializza SemanticChunker ===\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"gradient\"\n",
    ")\n",
    "\n",
    "# === Inizializza Gliner ===\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\")\n",
    "model.eval()\n",
    "labels = [\"person\", \"company\", \"location\", \"date\", \"position\", \"email\", \"phone\", \"legal_entity\", \"contract_number\"]\n",
    "\n",
    "# === Funzione per processare un documento ===\n",
    "def process_document(file_path, output_folder):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # 1. Semantic chunking grezzo\n",
    "    raw_chunks = semantic_chunker.create_documents([text])\n",
    "\n",
    "    # 2. Ricostruisco start/end di ciascun chunk nel testo originale per evitare di spezzare entitÃ \n",
    "    chunks_with_pos = []\n",
    "    offset = 0\n",
    "    for doc in raw_chunks:\n",
    "        content = doc.page_content\n",
    "        start = offset\n",
    "        end = offset + len(content)\n",
    "        chunks_with_pos.append({\"start\": start, \"end\": end})\n",
    "        offset = end\n",
    "\n",
    "    # 3. Estraggo entitÃ  con Gliner\n",
    "    entities = model.predict_entities(text, labels=labels, threshold=0.4)\n",
    "\n",
    "    # 4. Correggo i confini dei chunk per non spezzare le entitÃ \n",
    "    new_chunks = []\n",
    "    for i, chunk in enumerate(chunks_with_pos):\n",
    "        start = chunk[\"start\"]\n",
    "        end = chunk[\"end\"]\n",
    "\n",
    "        # se il chunk finisce in mezzo a un'entitÃ , sposto la fine\n",
    "        for ent in entities:\n",
    "            if ent[\"start\"] < end < ent[\"end\"]:\n",
    "                end = ent[\"end\"]\n",
    "                break\n",
    "\n",
    "        new_chunks.append(text[start:end])\n",
    "\n",
    "        # aggiorno l'inizio del chunk successivo\n",
    "        if i + 1 < len(chunks_with_pos):\n",
    "            chunks_with_pos[i + 1][\"start\"] = end\n",
    "\n",
    "    # 5. Salvo i chunk finali\n",
    "    file_name = os.path.basename(file_path)\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    output_file = os.path.join(output_folder, f\"{base_name}_chunks.md\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, c in enumerate(new_chunks):\n",
    "            f.write(f\"### Chunk {i + 1}\\n\\n\")\n",
    "            f.write(c.strip() + \"\\n\\n\")\n",
    "\n",
    "    print(f\"âœ… File salvato: {output_file} ({len(new_chunks)} chunk)\")\n",
    "\n",
    "# === Esecuzione su tutti i file della cartella ===\n",
    "for file_name in os.listdir(SOURCE_FOLDER):\n",
    "    file_path = os.path.join(SOURCE_FOLDER, file_name)\n",
    "    if os.path.isfile(file_path) and file_name.lower().endswith('.md'):\n",
    "        process_document(file_path, OUTPUT_FOLDER)\n",
    "\n",
    "print(\"\\nâœ… Tutti i documenti processati.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d1d4f",
   "metadata": {},
   "source": [
    "# APPLICAZIONE TABELLE E IMMAGINI DENTRO I PLACEHOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f86c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 6.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 7.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 2.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 9.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 19.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 1.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 14.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 4.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 15.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 17.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 18.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 1.1.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 21.md\n",
      "Manca contenuto per [[IMAGE-1]] (file base: FAC-SIMILE 13)\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 13.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 16.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 10.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 8.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 20.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 5.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 11.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 3.md\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE Validazione.md\n",
      "Manca contenuto per [[IMAGE-1]] (file base: FAC-SIMILE 12)\n",
      "Creato /storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image/FAC-SIMILE 12.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# cartelle principali\n",
    "template_dir = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunks\"      # markdown con placeholder\n",
    "content_dir = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/descrizioni\"       # cartella con sottocartelle di tabelle/immagini\n",
    "output_dir = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image\" # dove scrivere i risultati\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# regex per i placeholder del tipo [[IMAGE-1]] [[TABLE-3]]\n",
    "placeholder_pattern = re.compile(r\"\\[\\[(IMAGE|TABLE)-(\\d+)\\]\\]\")\n",
    "\n",
    "def find_content_file(base_name, kind, num):\n",
    "    \"\"\"\n",
    "    Cerca ricorsivamente nei contenuti un file che corrisponde al pattern:\n",
    "    base_name + \"-\" + tipo + \"-\" + num + \".txt\"\n",
    "    dove tipo Ã¨ in minuscolo (table/picture).\n",
    "    \"\"\"\n",
    "    kind_map = {\"IMAGE\": \"picture\", \"TABLE\": \"table\"}\n",
    "    expected_name = f\"{base_name}-{kind_map[kind]}-{num}.txt\"\n",
    "\n",
    "    for root, _, files in os.walk(content_dir):\n",
    "        for f in files:\n",
    "            if f == expected_name:\n",
    "                return os.path.join(root, f)\n",
    "    return None\n",
    "\n",
    "for filename in os.listdir(template_dir):\n",
    "    if filename.endswith(\"-with-placeholders_chunks.md\"):\n",
    "        template_path = os.path.join(template_dir, filename)\n",
    "\n",
    "        # estraggo il \"base_name\" eliminando \"-with-placeholders_chunks.md\"\n",
    "        base_name = filename.replace(\"-with-placeholders_chunks.md\", \"\")\n",
    "\n",
    "        with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # cerco i placeholder nel testo\n",
    "        matches = placeholder_pattern.findall(content)\n",
    "\n",
    "        for kind, num in matches:\n",
    "            file_path = find_content_file(base_name, kind, num)\n",
    "            placeholder = f\"[[{kind}-{num}]]\"\n",
    "\n",
    "            if file_path:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    replacement = f.read()\n",
    "\n",
    "                # creo il blocco completo\n",
    "                wrapped = f\"{placeholder} START\\n{replacement}\\n{placeholder} END\"\n",
    "                content = content.replace(placeholder, wrapped)\n",
    "            else:\n",
    "                print(f\"Manca contenuto per {placeholder} (file base: {base_name})\")\n",
    "\n",
    "        # salvo l'output\n",
    "        out_path = os.path.join(output_dir, f\"{base_name}.md\")\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        print(f\"Creato {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626fe44",
   "metadata": {},
   "source": [
    "# RETRIEVAL E RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e85d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ 'FAC-SIMILE 12.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 12.md\n",
      "ðŸ”„ 'FAC-SIMILE 4.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 4.md\n",
      "ðŸ”„ 'FAC-SIMILE 18.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 18.md\n",
      "ðŸ”„ 'FAC-SIMILE 21.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 21.md\n",
      "ðŸ”„ 'FAC-SIMILE 15.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 15.md\n",
      "ðŸ”„ 'FAC-SIMILE 20.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 20.md\n",
      "ðŸ”„ 'FAC-SIMILE 1.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 1.md\n",
      "ðŸ”„ 'FAC-SIMILE 8.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 8.md\n",
      "ðŸ”„ 'FAC-SIMILE 6.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 6.md\n",
      "ðŸ”„ 'FAC-SIMILE 11.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 11.md\n",
      "ðŸ”„ 'FAC-SIMILE 17.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 17.md\n",
      "ðŸ”„ 'FAC-SIMILE 2.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 2.md\n",
      "ðŸ”„ 'FAC-SIMILE 13.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 13.md\n",
      "ðŸ”„ 'FAC-SIMILE 14.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 14.md\n",
      "ðŸ”„ 'FAC-SIMILE 10.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 10.md\n",
      "ðŸ”„ 'FAC-SIMILE 9.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 9.md\n",
      "ðŸ”„ 'FAC-SIMILE 16.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 16.md\n",
      "ðŸ”„ 'FAC-SIMILE 7.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 7.md\n",
      "ðŸ”„ 'FAC-SIMILE Validazione.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE Validazione.md\n",
      "ðŸ”„ 'FAC-SIMILE 1.1.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 1.1.md\n",
      "ðŸ”„ 'FAC-SIMILE 5.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 5.md\n",
      "ðŸ”„ 'FAC-SIMILE 19.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 19.md\n",
      "ðŸ”„ 'FAC-SIMILE 3.md' modificato. Re-indicizzazione in corso...\n",
      "âœ… Indicizzazione completata per FAC-SIMILE 3.md\n",
      "\n",
      "âœ… Tutti i documenti sono stati indicizzati.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import requests\n",
    "import hashlib\n",
    "\n",
    "# === CONFIG ===\n",
    "MD_FOLDER = \"/storage/data_4T_b/andreacutuli/PROVA/Documents/markdown_chunk_placeholders_table_image\"\n",
    "CHROMA_PATH = os.path.expanduser(\"~/chroma_docs_db\")\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "os.makedirs(CHROMA_PATH, exist_ok=True)\n",
    "\n",
    "# === Setup ChromaDB ===\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "collection_name = \"document_qa_collection\"\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "# === FUNZIONI DI UTILITÃ€ ===\n",
    "def get_ollama_embedding(text):\n",
    "    try:\n",
    "        response = requests.post(f\"{OLLAMA_URL}/embeddings\", json={\"model\": EMBED_MODEL, \"prompt\": text}).json()\n",
    "        return response.get(\"embedding\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Errore generando embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_file_hash(filepath):\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "def index_md_file(md_filepath):\n",
    "    \"\"\"Indicizza un singolo file Markdown giÃ  diviso in chunk ### Chunk\"\"\"\n",
    "    with open(md_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    file_hash = calculate_file_hash(md_filepath)\n",
    "    filename = os.path.basename(md_filepath)\n",
    "\n",
    "    # Controlla se il file Ã¨ giÃ  presente e non Ã¨ cambiato\n",
    "    existing_docs = collection.get(where={\"filename\": filename}, include=[\"metadatas\"])\n",
    "    if existing_docs and \"metadatas\" in existing_docs and existing_docs[\"metadatas\"]:\n",
    "        stored_hashes = {meta.get(\"file_hash\") for meta in existing_docs[\"metadatas\"] if \"file_hash\" in meta}\n",
    "        if file_hash in stored_hashes:\n",
    "            print(f\"âœ”ï¸ '{filename}' non Ã¨ cambiato. Saltato.\")\n",
    "            return\n",
    "        else:\n",
    "            collection.delete(where={\"filename\": filename})\n",
    "            print(f\"ðŸ”„ '{filename}' modificato. Re-indicizzazione in corso...\")\n",
    "\n",
    "    raw_chunks = [chunk.strip() for chunk in content.split(\"### Chunk\") if chunk.strip()]\n",
    "    \n",
    "    for i, chunk_text in enumerate(raw_chunks):\n",
    "        chunk_id = f\"{filename}_chunk{i+1}\"\n",
    "        embedding = get_ollama_embedding(chunk_text)\n",
    "        if embedding is None:\n",
    "            continue\n",
    "        collection.upsert(\n",
    "            ids=[chunk_id],\n",
    "            documents=[chunk_text],\n",
    "            embeddings=[embedding],\n",
    "            metadatas={\"filename\": filename, \"file_hash\": file_hash}\n",
    "        )\n",
    "    print(f\"âœ… Indicizzazione completata per {filename}\")\n",
    "\n",
    "# === Indicizza tutti i file Markdown nella cartella ===\n",
    "for file_name in os.listdir(MD_FOLDER):\n",
    "    file_path = os.path.join(MD_FOLDER, file_name)\n",
    "    if os.path.isfile(file_path) and file_name.lower().endswith(\".md\"):\n",
    "        index_md_file(file_path)\n",
    "\n",
    "print(\"\\nâœ… Tutti i documenti sono stati indicizzati.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47c904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Risposta sintetica:\n",
      " Rischi: Nel portafoglio proposto da Finvest Advisory S.r.l., i principali rischi da considerare sono il rischio di mercato, che puÃ² determinare potenziali perdite temporanee o perde di capitalizzazione, e il rischio di asset specifici correlati al tipo di investimento selezionato (ad esempio, il rischio associato alle azioni ad alta crescita nel profilo aggressivo).\n",
      "\n",
      "Guadagni Attesi: Le proiezioni di rendimento sono diverse a seconda del profilo di investimento scelto. Nel caso del profilo moderato, ad esempio, si prevede un reddito medio annuo del 5-7%. Tuttavia, i guadagni attesi possono variare in funzione delle condizioni di mercato e delle modifiche che avvengono nella strategia di investimento.\n",
      "\n",
      "Capitale Minimo di Investimento: Per garantire una corretta diversificazione del portafoglio e una gestione efficiente degli asset, il capitale minimo richiesto varia in base al profilo di rischio:\n",
      "- Profilo conservativo: investimento minimo di 20.000 â‚¬\n",
      "- Profilo moderato: investimento minimo di 50.000 â‚¬\n",
      "- Profilo aggressivo: investimento minimo di 100.000 â‚¬\n",
      "\n",
      "ðŸ“š Chunk utilizzati e file di origine:\n",
      "- File: FAC-SIMILE 15.md\n",
      "  Chunk estratto: 2\n",
      "\n",
      "per la gestione e l'ottimizzazione dei suoi  investimenti.  Il  nostro  obiettivo  Ã¨  fornirle  una  proposta  d'investimento  personalizzata, basa...\n",
      "- File: FAC-SIMILE 15.md\n",
      "  Chunk estratto: 5\n",
      "\n",
      "ETF diversificati, 10% liquiditÃ .\n",
      "\n",
      "â— Profilo  Moderato :  40%  obbligazioni,  40%  azioni  globali,  10%  ETF  settoriali,  10% investimenti altern...\n",
      "- File: FAC-SIMILE 15.md\n",
      "  Chunk estratto: 4\n",
      "\n",
      "nvest Advisory S.r.l. Ã¨ una societÃ  di consulenza finanziaria con sede a Milano, specializzata nella gestione patrimoniale e nella pianificazione s...\n",
      "- File: FAC-SIMILE 5.md\n",
      "  Chunk estratto: 3\n",
      "\n",
      "mercato immobiliare.\n",
      "\n",
      "SmartFinance  S.r.l. rimane  a  disposizione  per  approfondimenti  e  definizione  di  ulteriori dettagli operativi.\n",
      "\n",
      "Cordia...\n",
      "- File: FAC-SIMILE 14.md\n",
      "  Chunk estratto: 4\n",
      "\n",
      "a elettrica grazie all'autoconsumo.\n",
      "\n",
      "â— Tempo di ritorno dell'investimento (Payback Period): Stima del periodo necessario per recuperare l'investime...\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "LLM_MODEL = \"mistral\"\n",
    "\n",
    "# === RAG con retrieval a livello di chunk ===\n",
    "\n",
    "def query_documents_chunks(question, n_results=3):\n",
    "    \"\"\"Recupera i chunk piÃ¹ rilevanti per la domanda\"\"\"\n",
    "    query_embedding = get_ollama_embedding(question)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=['metadatas', 'documents']\n",
    "    )\n",
    "\n",
    "    retrieved_chunks = []\n",
    "    if \"documents\" in results and results[\"documents\"]:\n",
    "        for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "            retrieved_chunks.append({\n",
    "                \"chunk_text\": doc,\n",
    "                \"filename\": meta.get(\"filename\", \"Sconosciuto\")\n",
    "            })\n",
    "    return retrieved_chunks\n",
    "\n",
    "def generate_response_from_chunks(question, retrieved_chunks):\n",
    "    \"\"\"Genera risposta usando solo i chunk rilevanti\"\"\"\n",
    "    context = \"\\n\\n\".join([c[\"chunk_text\"] for c in retrieved_chunks])\n",
    "    prompt = (\n",
    "        \"You are an assistant for question-answering tasks. Use the following pieces of \"\n",
    "        \"retrieved context (chunks) to answer the question. \"\n",
    "        \"If you don't know the answer, say that you don't know. \"\n",
    "        \"The answer should be in italian.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    "    )\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_URL}/chat\",\n",
    "            json={\n",
    "                \"model\": LLM_MODEL,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"âš ï¸ Errore durante la generazione della risposta: {e}\"\n",
    "\n",
    "# === ESEMPIO DI USO ===\n",
    "question = \"Rischi, Guadagni Attesi e Capitale Minimo di Investimento nei vari profili di investimento\"\n",
    "retrieved_chunks = query_documents_chunks(question, n_results=5)  # puoi aumentare il numero di chunk\n",
    "\n",
    "if not retrieved_chunks:\n",
    "    print(\"âš ï¸ Nessun chunk rilevante trovato.\")\n",
    "else:\n",
    "    answer = generate_response_from_chunks(question, retrieved_chunks)\n",
    "    \n",
    "    print(\"\\nâœ… Risposta sintetica:\")\n",
    "    print(answer)\n",
    "    \n",
    "    print(\"\\nðŸ“š Chunk utilizzati e file di origine:\")\n",
    "    for chunk in retrieved_chunks:\n",
    "        print(f\"- File: {chunk['filename']}\")\n",
    "        print(f\"  Chunk estratto: {chunk['chunk_text'][:150]}...\")  # mostra solo i primi 150 caratteri\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
